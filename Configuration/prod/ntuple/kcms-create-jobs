#!/usr/bin/env python

import sys, os
import stat
from math import ceil

def usage():
    print sys.argv[0], " : create pbs jobs"
    print "  Options :"
    print "    --jobName NAME (Name of job)"
    print "    --dataset DATASET_NAME (should be present in UOS T3)"
    print "    --maxFiles N (Maximum number of files per job)"
    print "    --cfg CONFIG_FILE_cfg.py"
    sys.exit()

# Parse arguments
if len(sys.argv) < 2: usage()
opts = {}
args = []
for i in range(1, len(sys.argv)):
    arg = sys.argv[i]

    arg1, arg2 = None, None
    if len(arg) > 2 and arg[:2] == '--':
        if '=' in arg:
            arg1 = arg.split('=')[0]
            arg2 = '='.join(arg.split('=')[1:])
        elif i+1 < len(sys.argv):
            arg1 = arg
            arg2 = sys.argv[i+1]
            i += 1
        else:
            print "ERROR: Value must be followed after the option", arg
            sys.exit()
        opts[arg1] = arg2
    elif arg[0] == '-':
        opts[arg] = True
    else:
        args.append(arg)
## Mandatory options
if '--jobName' not in opts: usage()
jobName = opts['--jobName']
if '--dataset' not in opts: usage()
datasetName = opts['--dataset']
if '--maxFiles' not in opts: usage()
maxFiles = int(opts['--maxFiles'])
if '--cfg' not in opts: usage()
cfgFileName = opts['--cfg']
if '_cfg.py' != cfgFileName[-min(7,len(cfgFileName)):]: usage()
if not os.path.exists(cfgFileName):
    print "ERROR: Cannot find config file", cfgFileName
    sys.exit()
if os.path.isdir(jobName):
    print "ERROR: Output directory already exists."
    sys.exit()

## Prepare working directory
print "@@ Preparing batch jobs in", jobName, "..."
os.makedirs(jobName)

## Get file list from DBS
print "@@ Retriving file list of dataset..."
dbsURL = 'http://cmsdbsprod.cern.ch/cms_dbs_ph_analysis_01/servlet/DBSServlet'
query = "find file where dataset = %s" % datasetName
os.system("dbs search --url='%s' --query='%s' --noheader > %s/files.txt" % (dbsURL, query, jobName))
## Collect root files
files = []
for f in open("%s/files.txt" % jobName).readlines():
    f = f.strip()
    if len(f) < 5: continue
    if '#' == f[0] or '.root' != f[-5:]: continue
    files.append(f)
nFiles = len(files)
if nFiles == 0:
    print "ERROR: Empty dataset."
    sys.exit()
## Sort files by its key "i", filename_[i]_[j]_hash.root
files.sort(key=lambda f: int(f.split('/')[-1].split('_')[1]))
    
## Load cfg file
print "@@ Loading python cfg..."
sys.path.append('.')
cout = sys.stdout
sys.stdout = open("%s/log.txt" % jobName, "w")
process = __import__('.'.join(cfgFileName.split('.')[:-1])).process
sys.stdout = cout

## Memorise to modify output file names
print "@@ Setting output modules..."
outFileModes = {}
if hasattr(process, 'TFileService'):
    outFileModes['TFileService'] = process.TFileService.fileName.value()
for modName in process.outputModules_():
    outFileModes[modName] = getattr(process, modName).fileName.value()

## Split files into jobs and write python cfg
print "@@ Splitting jobs..."
for section in range(int(ceil(1.0*nFiles/maxFiles))):
    begin = section*maxFiles
    end = min(begin+maxFiles, nFiles)

    process.source.fileNames = files[begin:end]
    for modName in outFileModes:
        getattr(process, modName).fileName = "%s_%03d.root" % (outFileModes[modName][:-5], section)

    cfgFileName = "%s/ntuple_%03d_cfg.py" % (jobName, section)
    open(cfgFileName, "w").write(process.dumpPython())

## Write run script
print "@@ Writing run script..."
runFileName = "%s/run.sh" % jobName
fout = open(runFileName, "w")
print>>fout, """#!/bin/bash
SECTION=`printf %%03d $1`
cd %s
eval `scram runtime -sh`
cd %s
time cmsRun ntuple_${SECTION}_cfg.py""" % (os.environ["CMSSW_BASE"], os.path.abspath(jobName))
fout = None
os.chmod(runFileName, os.stat(runFileName).st_mode | stat.S_IEXEC)

print "@@ Done."
